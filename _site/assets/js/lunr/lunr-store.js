var store = [{
        "title": "Sparse Autoencoders for Improving Unlearning in Large Language Models",
        "excerpt":"A.K.A: Smallish Large-Language Models: What Do They Know? Can They Un-Know Things?? Let’s Find Out.  Colab Notebook  Key Takeaways I am confident that this approach works. SAE unlearning significantly reduces the likelihood a model predicts tokens related to a specified topic. I am reasonably confident that the approach will generalize...","categories": [],
        "tags": ["AI","coding","coding/projects"],
        "url": "/unlearning1",
        "teaser": null
      },{
        "title": "Execution Failures are Still Failures (Calibrate Surprise by Making Weird Excuses)",
        "excerpt":"“Almost only counts in horseshoes and hand grenades” — Frank Robinson When I was studying for the GRE, I observed a rationalization process in my mind. It happened most often when I screwed up a small detail on a problem I felt I understood. If, for example, I quickly calculated...","categories": [],
        "tags": ["principles","productivity"],
        "url": "/errors",
        "teaser": null
      }]
